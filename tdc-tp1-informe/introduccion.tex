\section{Introducción}

	
Existen situaciones en las que se desea conocer la topología de una red con el fin de determinar nodos distinguidos dentro de la misma.
Por ejemplo, podría necesitarse encontrar cual es la direccíon IP del gateway utilizado en la red; o determinar la dirección de un servidor de base de datos.
Si bien los paquetes IP enviados no contienen dicha información \textsl{per se}, ésta puede obtenerse analizando el flujo de paquetes ARP que viajan por la red. 
ARP (\textsl{Address Resolution Protocol}) es un protocolo de control ideado para mapear direcciones IP (capa 3) con direcciones fisicas (capa 2); en el caso de de una red Ethernet, ARP es utilizado para mapear direcciones IP con direcciones MAC.
La utilización de ARP genera un tabla cache de traducción que es utilizada como referencia. 
El protocolo consiste básicamente en los siguientes pasos:

\begin{enumerate}
	\item Un host \textbf{A} desea enviar un paquete a una determinada IP. Si tiene la dirección IP en su cache, utiliza la direccion física almacenada; si no, envía un mensaje broadcast dentro de la red (en Ethernet, MAC destino = FF:FF:FF:FF) y aguarda la respuesta. Este mensaje se conoce como \textbf{ARP request}.
	\item Si dentro de la red existe un host B que sabe como direccionar a la direccion IP requerida, responde al mensaje ARP request con un mensaje \textbf{ARP reply} que indica su dirección física. Este host puede ser el dueño de la dirección IP, o un host intermediario como un router.
	\item \textbf{A} recibe el ARP reply de \textbf{B}, actualiza su cache y envía el paquete original utilizando la dirección física de \textbf{B}.
\end{enumerate}

En este informe mostraremos como podemos utilizar la información provista en los paquetes ARP para analizar la topología de una red.

\subsection{Información y Fuente de información}

Dado un evento E con probabilidad \textsl{P(E)}, se define la \textbf{información del evento E} como

\begin{center}
$I(E)=-\log{P(E)}$ 
\end{center}

I(E) es una medida de la cantidad de información que obtenemos por la ocurrencia de E: mientras más improbable sea E, mayor será la información brindada por su ocurrencia. Dicho de otra manera, si sabemos que un evento E tiene alta probabilidad de ocurrir, entonces su ocurrencia no aportará mucha información sobre lo que se esta observando.

Por otro lado, una fuente de información es todo aquello que emite mensajes de acuerdo a una ley de probabilidad fija; los mensajes pertenecen a un conjunto finito de símbolos $S={s_{1},...,s_{n}}$, conocido como el alfabeto de la fuente, y la fuente en si misma está definida por su alfabeto. En este contexo, cada emisión de un mensaje representa un evento que aporta información.


\subsection{Entropía}

La entropía de una fuente de información mide la incertidumbre de la fuente.
Dada una fuente de informacion $S={s_{1},...,s_{n}}$, se define la entropía de S como la suma ponderada de la información de casa simbolo de S,

$$H(S)=\sum^{n}_{i=1}{P(s_{i})*I(s_{i})}$$





